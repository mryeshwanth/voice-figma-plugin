<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Voice Transcription</title>
  <script src="https://cdn.tailwindcss.com"></script>
</head>
<body class="font-sans m-0 p-5 max-w-2xl mx-auto leading-normal">
  <!-- Page header with clear instructions -->
  <header class="mb-5">
    <h1 class="text-2xl font-bold text-gray-800">Voice to Text</h1>
    <p class="text-gray-600">Click "Record" to begin speaking. Your text will appear below.</p>
  </header>

  <!-- Microphone access warning with detailed instructions for different OS/browsers -->
  <div id="mic-warning" class="hidden bg-blue-50 text-blue-800 border border-blue-200 rounded-lg p-4 mb-5" role="alert" aria-atomic="true">
    <h3 class="font-bold text-lg mb-2">Microphone Access Required</h3>
    <ul class="list-disc pl-5">
      <li><strong>Windows:</strong> Settings → Privacy → Microphone → Allow access</li>
      <li><strong>Mac:</strong> System Settings → Privacy & Security → Microphone → Enable for your browser</li>
      <li><strong>Chrome/Edge:</strong> Click lock icon → Site Settings → Allow Microphone</li>
      <li><strong>Safari:</strong> Preferences → Websites → Microphone → Allow</li>
    </ul>
    <p class="mt-2">After allowing access, refresh this page.</p>
  </div>

  <!-- Browser compatibility warning -->
  <div id="browser-warning" class="hidden bg-yellow-50 text-yellow-800 border border-yellow-200 rounded-lg p-4 mb-5" role="alert" aria-atomic="true"></div>
  
  <!-- Time limit warning -->
  <div id="limit-warning" class="hidden bg-yellow-50 text-yellow-800 border border-yellow-200 rounded-lg p-4 mb-5" role="alert" aria-live="assertive" aria-atomic="true">
    You're approaching the 60-second limit. Recording will stop soon.
  </div>

  <!-- Recording indicator with ARIA live region -->
  <div id="recording-indicator" class="hidden flex items-center justify-center my-4 h-8" role="status" aria-live="assertive" aria-atomic="true">
    <div class="recording-dot w-4 h-4 bg-red-600 rounded-full mr-3 animate-pulse" aria-hidden="true"></div>
    <span>Recording in progress</span>
  </div>
  
  <!-- Timer with ARIA role -->
  <div id="timer" class="font-mono text-xl text-center my-3" role="timer" aria-label="Recording time" aria-live="polite">0:00</div>

  <!-- Controls section -->
  <div class="flex flex-col items-center my-4">
    <!-- Record/Stop button with ARIA states -->
    <button id="action-btn" class="hidden bg-blue-600 hover:bg-blue-700 text-white py-2 px-4 rounded-md font-medium min-w-32 mb-3" aria-controls="transcription" aria-pressed="false">Record</button>
    
    <!-- Language selector with visible label -->
    <div class="mt-4 text-center w-full">
      <label for="language-select" class="block mb-1 font-medium text-gray-700">Choose Language</label>
      <div class="flex max-w-xs mx-auto">
        <select id="language-select" class="py-2 px-3 rounded-l-md border border-gray-300 w-full">
          <<option value="ar-SA">Arabic (العربية)</option>
          <option value="zh-CN">Chinese (简体中文)</option>
          <option value="nl-NL">Dutch (Nederlands)</option>
          <option value="en-GB">English (UK)</option>
          <option value="en-US">English (US)</option>
          <option value="fr-FR">French (Français)</option>
          <option value="de-DE">German (Deutsch)</option>
          <option value="hi-IN">Hindi (हिंदी)</option>
          <option value="it-IT">Italian (Italiano)</option>
          <option value="ja-JP">Japanese (日本語)</option>
          <option value="ko-KR">Korean (한국어)</option>
          <option value="pt-BR">Portuguese (Português)</option>
          <option value="ru-RU">Russian (Русский)</option>
          <option value="es-ES">Spanish (Español)</option>          
        </select>
        <button id="check-support-btn" class="bg-gray-100 border border-gray-300 border-l-0 text-gray-700 px-2 rounded-r-md hover:bg-gray-200" title="Check language support" aria-label="Check language support">
          <svg xmlns="http://www.w3.org/2000/svg" class="h-5 w-5" fill="none" viewBox="0 0 24 24" stroke="currentColor">
            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13 16h-1v-4h-1m1-4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z" />
          </svg>
        </button>
      </div>
      <p class="text-sm text-amber-600 mt-2">Note: Language support varies by browser. English has the best support across all browsers.</p>
    </div>
  </div>
  
  <!-- Transcription area with proper labeling -->
  <div class="w-full">
    <label for="transcription" class="block mb-1 font-medium text-gray-700">Transcribed Text</label>
    <textarea id="transcription" placeholder="Your transcription will appear here..." class="hidden w-full h-48 border border-gray-300 rounded-md p-3 font-sans text-base" aria-live="polite"></textarea>
  </div>

  <!-- Keyboard shortcuts help section -->
  <div id="keyboard-shortcuts" class="hidden bg-blue-50 text-blue-800 border border-blue-200 rounded-lg p-4 mt-5">
    <h3 class="font-bold text-lg mb-2">Keyboard Shortcuts</h3>
    <ul class="space-y-1">
      <li><kbd class="px-2 py-1 text-xs font-semibold bg-gray-100 border border-gray-300 rounded-md">Space</kbd> or <kbd class="px-2 py-1 text-xs font-semibold bg-gray-100 border border-gray-300 rounded-md">Enter</kbd>: Start/Stop recording when button is focused</li>
      <li><kbd class="px-2 py-1 text-xs font-semibold bg-gray-100 border border-gray-300 rounded-md">Ctrl</kbd> + <kbd class="px-2 py-1 text-xs font-semibold bg-gray-100 border border-gray-300 rounded-md">R</kbd>: Toggle recording from anywhere</li>
      <li><kbd class="px-2 py-1 text-xs font-semibold bg-gray-100 border border-gray-300 rounded-md">Ctrl</kbd> + <kbd class="px-2 py-1 text-xs font-semibold bg-gray-100 border border-gray-300 rounded-md">S</kbd>: Send transcription to Figma</li>
      <li><kbd class="px-2 py-1 text-xs font-semibold bg-gray-100 border border-gray-300 rounded-md">Escape</kbd>: Cancel current transcription</li>
    </ul>
  </div>

  <!-- Screen reader only utilities -->
  <div class="sr-only absolute w-px h-px overflow-hidden" aria-hidden="true"></div>

  <script>
    const actionBtn = document.getElementById('action-btn');
    const transcriptionBox = document.getElementById('transcription');
    const micWarning = document.getElementById('mic-warning');
    const browserWarning = document.getElementById('browser-warning');
    const indicator = document.getElementById('recording-indicator');
    const limitWarning = document.getElementById('limit-warning');
    const timerEl = document.getElementById('timer');
    const languageSelect = document.getElementById('language-select');
    const keyboardShortcuts = document.getElementById('keyboard-shortcuts');
    const session = new URLSearchParams(window.location.search).get('session');

    let recognition;
    let isRecording = false;
    let isFinished = false;
    let finalTranscript = '', interimTranscript = '';
    let autoRestart = true;
    let timerInterval = null;
    let totalSeconds = 0;
    const MAX_SECONDS = 60;

    function formatTime(secs) {
      const m = Math.floor(secs / 60);
      const s = secs % 60;
      return `${m}:${s.toString().padStart(2, '0')}`;
    }

    function startTimer() {
      totalSeconds = 0;
      limitWarning.classList.add('hidden');
      timerEl.textContent = '0:00';
      timerEl.setAttribute('aria-label', 'Recording time: 0 minutes 0 seconds');

      timerInterval = setInterval(() => {
        totalSeconds++;
        timerEl.textContent = formatTime(totalSeconds);
        
        // Update ARIA label for screen readers with current time
        const minutes = Math.floor(totalSeconds / 60);
        const seconds = totalSeconds % 60;
        timerEl.setAttribute('aria-label', `Recording time: ${minutes} minute${minutes !== 1 ? 's' : ''} ${seconds} second${seconds !== 1 ? 's' : ''}`);

        if (totalSeconds === MAX_SECONDS - 15) {
          limitWarning.classList.remove('hidden');
          // Announce limit warning to screen readers
          const ariaLive = document.createElement('div');
          ariaLive.setAttribute('aria-live', 'assertive');
          ariaLive.className = 'sr-only';
          ariaLive.textContent = 'Warning: 15 seconds remaining before recording auto-stops';
          document.body.appendChild(ariaLive);
          setTimeout(() => document.body.removeChild(ariaLive), 3000);
        }

        if (totalSeconds >= MAX_SECONDS) {
          autoRestart = false;
          recognition.stop();
        }
      }, 1000);
    }

    function stopTimer() {
      clearInterval(timerInterval);
      timerInterval = null;
    }

    // Improved browser detection with more detailed feedback
    const browserInfo = (() => {
      const ua = navigator.userAgent;
      if (/chrome/i.test(ua) && !/edg/i.test(ua) && !/opr/i.test(ua)) {
        return { name: "Google Chrome", supported: true };
      } else if (/edg/i.test(ua)) {
        return { name: "Microsoft Edge", supported: true };
      } else if (/firefox/i.test(ua)) {
        return { name: "Firefox", supported: false, reason: "Firefox requires special permissions for speech recognition." };
      } else if (/safari/i.test(ua) && !/chrome|chromium/i.test(ua)) {
        return { name: "Safari", supported: true };
      } else if (/opr/i.test(ua) || /opera/i.test(ua)) {
        return { name: "Opera", supported: true };
      } else {
        return { name: "Unknown", supported: false, reason: "This browser is not supported for speech recognition." };
      }
    })();

    const isSpeechSupported = 'webkitSpeechRecognition' in window || 'SpeechRecognition' in window;

    // Enhanced keyboard shortcuts handling
    document.addEventListener('keydown', (e) => {
      // Space or Enter to toggle recording when focused on action button
      if ((e.key === ' ' || e.key === 'Enter') && document.activeElement === actionBtn) {
        e.preventDefault();
        actionBtn.click();
      }
      
      // Ctrl+R to toggle recording from anywhere when transcription is visible
      if (e.ctrlKey && e.key === 'r' && !transcriptionBox.classList.contains('hidden')) {
        e.preventDefault();
        actionBtn.click();
      }
      
      // Ctrl+S to send transcription to Figma when in finished state
      if (e.ctrlKey && e.key === 's' && isFinished) {
        e.preventDefault();
        actionBtn.click();
      }
      
      // Escape to cancel current transcription during recording
      if (e.key === 'Escape' && isRecording) {
        e.preventDefault();
        autoRestart = false;
        recognition.stop();
        announceToScreenReader('Recording cancelled');
      }
      
      // Show/hide keyboard shortcuts help with ? key
      if (e.key === '?') {
        e.preventDefault();
        keyboardShortcuts.classList.toggle('hidden');
      }
    });

    // Helper function for screen reader announcements
    function announceToScreenReader(message, priority = 'polite') {
      const ariaLive = document.createElement('div');
      ariaLive.setAttribute('aria-live', priority);
      ariaLive.className = 'sr-only';
      ariaLive.textContent = message;
      document.body.appendChild(ariaLive);
      setTimeout(() => document.body.removeChild(ariaLive), 3000);
    }

    if (!isSpeechSupported || !browserInfo.supported) {
      browserWarning.classList.remove('hidden');
      browserWarning.setAttribute('role', 'alert');
      
      let message = `
        <h3 class="font-bold text-lg mb-2">Browser Compatibility Issue</h3>
        <p>Your browser <strong>${browserInfo.name}</strong> does not support speech recognition.`;
        
      if (browserInfo.reason) {
        message += ` ${browserInfo.reason}`;
      }
      
      message += `</p>
        <p class="mt-2">Try using <strong>Google Chrome</strong>, <strong>Edge</strong>, or <strong>Safari</strong> instead.</p>
      `;
      
      browserWarning.innerHTML = message;
    } else {
      navigator.mediaDevices.getUserMedia({ audio: true })
        .then(stream => {
          micWarning.classList.add('hidden');
          actionBtn.classList.remove('hidden');
          transcriptionBox.classList.remove('hidden');
          keyboardShortcuts.classList.remove('hidden');

          const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
          recognition = new SpeechRecognition();
          recognition.continuous = true;
          recognition.interimResults = true;
          recognition.lang = languageSelect.value;

          // Update language when selection changes
          languageSelect.addEventListener('change', () => {
            if (recognition) {
              const wasRecording = isRecording;
              const selectedLanguageName = languageSelect.options[languageSelect.selectedIndex].text;
              
              if (wasRecording) {
                autoRestart = false;
                recognition.stop();
              }
              
              recognition.lang = languageSelect.value;
              
              if (wasRecording) {
                setTimeout(() => {
                  autoRestart = true;
                  recognition.start();
                }, 200);
              }
              
              // Announce language change to screen readers
              announceToScreenReader(`Language changed to ${selectedLanguageName}`);
            }
          });

          recognition.onstart = () => {
            isRecording = true;
            isFinished = false;
            indicator.classList.remove('hidden');
            actionBtn.textContent = 'Stop';
            actionBtn.setAttribute('aria-pressed', 'true');
            actionBtn.setAttribute('aria-label', 'Stop recording');
            actionBtn.classList.remove('bg-blue-600', 'hover:bg-blue-700');
            actionBtn.classList.add('bg-red-600', 'hover:bg-red-700');
            startTimer();
            announceToScreenReader('Recording started', 'assertive');
          };

          recognition.onresult = (event) => {
            interimTranscript = '';
            for (let i = event.resultIndex; i < event.results.length; ++i) {
              const transcript = event.results[i][0].transcript;
              event.results[i].isFinal ? finalTranscript += transcript + ' ' : interimTranscript += transcript;
            }
            transcriptionBox.value = finalTranscript + interimTranscript;
            
            // Ensure the textbox scrolls to show latest content
            transcriptionBox.scrollTop = transcriptionBox.scrollHeight;
          };

          recognition.onend = () => {
            stopTimer();
            indicator.classList.add('hidden');
            limitWarning.classList.add('hidden');

            if (isRecording && autoRestart) {
              recognition.start();
            } else {
              isRecording = false;
              isFinished = true;
              actionBtn.textContent = 'Send to Figma';
              actionBtn.setAttribute('aria-pressed', 'false');
              actionBtn.setAttribute('aria-label', 'Send transcription to Figma');
              actionBtn.classList.remove('bg-red-600', 'hover:bg-red-700');
              actionBtn.classList.add('bg-green-600', 'hover:bg-green-700');
              
              // Announce recording stopped to screen readers
              announceToScreenReader('Recording stopped. Review and send to Figma.', 'assertive');
            }
          };

          recognition.onerror = (event) => {
            stopTimer();
            console.error('Speech error:', event.error);
            indicator.classList.add('hidden');
            actionBtn.textContent = 'Record';
            actionBtn.setAttribute('aria-pressed', 'false');
            actionBtn.setAttribute('aria-label', 'Start recording');
            actionBtn.classList.remove('bg-red-600', 'hover:bg-red-700', 'bg-green-600', 'hover:bg-green-700');
            actionBtn.classList.add('bg-blue-600', 'hover:bg-blue-700');
            
            // Create accessible error message
            showError(getErrorMessage(event.error));
          };
          
          // Add language support checker
          function checkLanguageSupport() {
            const supportMsg = document.createElement('div');
            supportMsg.className = 'bg-blue-50 text-blue-800 border border-blue-200 rounded-lg p-4 mt-4';
            supportMsg.innerHTML = '<h3 class="font-bold">Current Language Support Status</h3>';
            
            const testRecognition = new SpeechRecognition();
            const langTest = document.createElement('ul');
            langTest.className = 'list-disc pl-5 mt-2';
            
            // Only test a few key languages to avoid overwhelming the user
            const languagesToTest = [
              {code: 'en-US', name: 'English (US)'},
              {code: languageSelect.value, name: languageSelect.options[languageSelect.selectedIndex].text}
            ];
            
            // Add the currently selected language if it's not English
            if (languageSelect.value !== 'en-US') {
              testRecognition.lang = languageSelect.value;
              langTest.innerHTML += `<li class="mb-1">Testing ${languageSelect.options[languageSelect.selectedIndex].text}...</li>`;
            } else {
              langTest.innerHTML += `<li class="mb-1">English (US) is fully supported.</li>`;
            }
            
            supportMsg.appendChild(langTest);
            supportMsg.innerHTML += '<p class="mt-2 text-sm">Note: For best results with non-English languages, use Chrome or Edge browsers and ensure you have the language pack installed on your system.</p>';
            
            // Add a close button
            const closeBtn = document.createElement('button');
            closeBtn.className = 'mt-2 bg-blue-100 text-blue-800 px-3 py-1 rounded text-sm';
            closeBtn.textContent = 'Close';
            closeBtn.onclick = () => supportMsg.remove();
            supportMsg.appendChild(closeBtn);
            
            document.body.appendChild(supportMsg);
          }

          // Helper function to get user-friendly error messages
          function getErrorMessage(errorType) {
            switch(errorType) {
              case 'no-speech':
                return 'No speech was detected. Please try again.';
              case 'audio-capture':
                return 'No microphone was found or microphone is disabled.';
              case 'not-allowed':
                return 'Microphone permission was denied. Please allow microphone access.';
              case 'network':
                return 'A network error occurred. Please check your connection.';
              case 'aborted':
                return 'Speech recognition was aborted.';
              case 'language-not-supported':
                return 'The selected language is not supported by your browser. Try using English or check the support info.';
              default:
                return 'An error occurred with speech recognition.';
            }
          }

          // Show error message with appropriate ARIA attributes
          function showError(message) {
            const errorMessage = document.createElement('div');
            errorMessage.setAttribute('role', 'alert');
            errorMessage.className = 'bg-red-50 text-red-800 border border-red-200 rounded-lg p-4 mb-5';
            errorMessage.textContent = message;
            document.body.insertBefore(errorMessage, actionBtn.parentNode);
            
            // Remove after 5 seconds
            setTimeout(() => {
              if (document.body.contains(errorMessage)) {
                document.body.removeChild(errorMessage);
              }
            }, 5000);
            
            // Announce to screen readers
            announceToScreenReader(message, 'assertive');
          }

          // Add language support check button functionality
          document.getElementById('check-support-btn').addEventListener('click', () => {
            checkLanguageSupport();
          });
          
          actionBtn.onclick = async () => {
            if (isFinished) {
              const text = transcriptionBox.value.trim();
              if (!text || !session) return;

              actionBtn.disabled = true;
              actionBtn.textContent = 'Sending...';
              actionBtn.setAttribute('aria-busy', 'true');
              
              try {
                announceToScreenReader('Sending transcription to Figma');
                
                const res = await fetch('/api/save-transcription', {
                  method: 'POST',
                  headers: { 'Content-Type': 'application/json' },
                  body: JSON.stringify({ sessionToken: session, text })
                });

                if (res.ok) {
                  // Announce to screen readers before redirecting
                  announceToScreenReader('Transcription sent successfully. Returning to Figma.', 'assertive');
                  
                  // Short delay to allow screen readers to announce
                  setTimeout(() => {
                    window.location.href = 'figma://';
                  }, 1000);
                } else {
                  throw new Error('Failed to send transcription');
                }
              } catch (err) {
                console.error(err);
                actionBtn.disabled = false;
                actionBtn.textContent = 'Send to Figma';
                actionBtn.setAttribute('aria-busy', 'false');
                
                showError('Error sending transcription. Please try again.');
              }
            } else if (!isRecording) {
              finalTranscript = '';
              interimTranscript = '';
              transcriptionBox.value = '';
              autoRestart = true;
              recognition.start();
            } else {
              autoRestart = false;
              recognition.stop();
            }
          };
        })
        .catch(() => {
          micWarning.classList.remove('hidden');
          actionBtn.classList.add('hidden');
          transcriptionBox.classList.add('hidden');
          
          // Focus on the microphone warning for screen readers
          setTimeout(() => {
            micWarning.setAttribute('tabindex', '-1');
            micWarning.focus();
            setTimeout(() => micWarning.removeAttribute('tabindex'), 100);
          }, 100);
        });
    }
  </script>
</body>
</html>